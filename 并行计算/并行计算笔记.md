---
notes of 并行计算
author:pyd
---

[TOC]

# 信息

* 教师：谭立湘
* 邮件：<tlx@ustc.edu.cn>
* 助教：夏鹏飞
* 邮件：<xpengfei@mail.ustc.edu.cn>
* qq群：736364765
* 没考试
* 参考书：并行计算与实现技术
* openMP, CUDA
* 课程报告自己选题，优秀者做PPT报告(8人左右)(成绩起点更高)，电子版发送到<tlx@ustc.edu.cn>
* 课程报告做openMP或CUDA。
* **眼动追踪技术**

# 并行计算

## 并行计算基础

* 将一个问题分解成多个子问题，分配给不同处理器，每个处理器承担计算任务的一部分，之间相互协作。

* unix常用命令：

  > pwd:当前工作目录
  >
  > mkdir:
  >
  > cd:
  >
  > rmdir:删除空目录
  >
  > ls:-l(详细信息),-a(包括隐含文件), > list信息导入文件
  >
  > cat:查看文本文件
  >
  > cp:拷贝文件，cp f1 f2; cp f1.c f2.c /home/user/lin
  >
  > mv:移动，改名 mv f1.c /home/user/wang; mv old.c new.c
  >
  > rm:删除文件 rm -r mydir(递归删除子目录)
  >
  > who:查看用户
  >
  >  ps:查看进程  pa -auxe(系统管理员可以查看所有人的进程)
  >
  > more:分页查看文本文件
  >
  > a.out <inputfile \>outputfile&, &表示投入后台，会返回一个进程给你。

* vi/vim

  > 命令

* lspci |grep -i nvidia查看gpu信息

### 任务分解

* 时间上并行（流水线）
* 空间上并行（矩阵分块）
* 考虑：负载均衡，通信量小。

### 三个基本条件

1. 并行机：包含多个处理器核心
2. 应用问题必须具有并行性
3. 并行编程

### 并行算法设计流程

* 任务划分
* 通信（比较慢）
* 任务组合
* 处理器映射（现已自动完成）

### 并行计算的基本术语

* 粒度：并行执行过程中，两次通信之间每个处理器工作量大小的一个粗略描述。

* 并行度：某一时刻多个处理器上可以同时执行的子任务数。

* 加速比：求解一个问题的最佳串行算法执行时间与并行算法的执行时间之比：(q为处理器数)
  $$
  S_{p}(q)=\frac{T_{s}}{T_{P}(q)}
  $$

* 并行效率：
  $$
  E_{p}(q)=\frac{S_{p}(q)}{q}
  $$

* 进程：运行中的程序，各个进程拥有独立的执行环境。

* 线程：一个进程可以含有多个线程，降低了系统管理的开销。

### 并行计算中的两个重要定律

1. Amdahl:假设串行计算的时间为$T_{s}=1$，$\alpha$为必需的串行部分百分比，那么
   $$
   S_{P}(q)=\frac{1}{\alpha+(1-\alpha)/q}
   $$
   加速比上限为$\frac{1}{\alpha}$ 当q为无穷大时达到。

2. Gustafson:假设并行计算所需要的时间为$T_{p}=1$ ,$\alpha$ 是执行该并行计算所必需的串行部分百分比，则：
   $$
   
   $$

### 高性能计算节点分类

* 同构节点：仅含同种类cpu
* 异构节点：分主机端和设备端，主流：cpu+gpu，cpu+mic(Inter集成众核)

## 基础并行算法

## 经典并行算法

## MPI

## openMP

## CUDA

